# -*- coding: utf-8 -*-
"""ACD(child).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aMgDNh4gQS8z2M0ENH3sphFhAvKJtdiT
"""

from google.colab import drive
drive.mount('/content/gdrive',force_remount=True)

import pandas as pd
data = pd.read_csv('/content/gdrive/MyDrive/data_csv.csv')

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import HistGradientBoostingClassifier

# Load the dataset
data = pd.read_csv('/content/gdrive/MyDrive/data_csv.csv')

# Data preprocessing
le = LabelEncoder()
for column in data.columns:
    if data[column].dtype == type(object):
        data[column] = le.fit_transform(data[column])

# Split the data into features and target

X = data.drop('ASD_traits', axis=1)
y = data['ASD_traits']


# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize classifiers
models = {
    "SVM": SVC(),
    "Naive Bayes": GaussianNB(),
    "Random Forest": RandomForestClassifier(),
    "KNN": KNeighborsClassifier()
}

from sklearn.impute import SimpleImputer
import numpy as np

# Impute missing values with the median
imputer = SimpleImputer(missing_values=np.nan ,strategy='median')

# Fit the imputer on the training data
imputer.fit(X_train)

# Transform both training and test data
X_train = imputer.transform(X_train)
X_test = imputer.transform(X_test)


# Train and evaluate each model
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Model: {name}")
    print(f"Accuracy: {accuracy}")
    print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
    print("="*50)


# Load the dataset
data = pd.read_csv('/content/gdrive/MyDrive/data_csv.csv')

# Data preprocessing
le = LabelEncoder()
for column in data.columns:
    if data[column].dtype == type(object):
        data[column] = le.fit_transform(data[column])

# Split the data into features and target
X = data.drop('ASD_traits', axis=1)
y = data['ASD_traits']

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the model
selected_model =  HistGradientBoostingClassifier()

# Train the model on the entire dataset
selected_model.fit(X_train, y_train)

# Ensure consistent feature names between training and prediction data
X_test = X_test.rename(columns={'Class/ASD': 'Class_ASD'})

# Predict whether the person has ASD or not
prediction = selected_model.predict(X_test)

# Interpret the prediction
if prediction[0] == 1:
    print("The person is likely suffering from ASD.")
else:
    print("The person is not likely suffering from ASD.")

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.model_selection import train_test_split

# ... (your previous code to load and preprocess data) ...

# Ensure X and y are defined
# Load the dataset
data = pd.read_csv('/content/gdrive/MyDrive/data_csv.csv')  # Assuming this is your data loading step

# Data preprocessing (if necessary)
# ...

# Split the data into features and target
X = data.drop('ASD_traits', axis=1)  # Define X
y = data['ASD_traits']  # Define y


# Split data into train and test sets (if not already done)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ... (rest of your code) ...

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
from sklearn.svm import SVC
from sklearn.impute import SimpleImputer # Import SimpleImputer
import numpy as np

# Load the dataset
data = pd.read_csv('/content/gdrive/MyDrive/data_csv.csv')

# Data preprocessing
le = LabelEncoder()
for column in data.columns:
    if data[column].dtype == type(object):
        data[column] = le.fit_transform(data[column])

# Split the data into features and target
X = data.drop('ASD_traits', axis=1)
y = data['ASD_traits']

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train a model (e.g., SVC) to get predictions
model = SVC()  # Initialize a model (e.g., SVC)


# Impute missing values with the median before Label Encoding
imputer = SimpleImputer(missing_values=np.nan, strategy='median')
X_train = imputer.fit_transform(X_train)
X_test = imputer.transform(X_test)

# Convert X_train and X_test back to DataFrames with original column names
X_train = pd.DataFrame(X_train, columns=X.columns)  # Get column names from original X
X_test = pd.DataFrame(X_test, columns=X.columns)    # Get column names from original X


# Now you can iterate through columns
for column in X_train.columns:
    if X_train[column].dtype == type(object):
        le = LabelEncoder()
        X_train[column] = le.fit_transform(X_train[column])
        X_test[column] = le.transform(X_test[column]) # Use the same encoder for X_test and use transform not fit_transform


model.fit(X_train, y_train)  # Train the model
y_pred = model.predict(X_test)  # Get predictions

# ... (rest of your code) ...

# Calculate ROC curves for each model
from sklearn import metrics
import matplotlib.pyplot as plt
roc_curves = {}
# Visualize ROC curves
plt.figure(figsize=(10, 8))
for name, curve_data in roc_curves.items():
    plt.plot(curve_data['fpr'], curve_data['tpr'], label=f"{name} (AUC = {curve_data['roc_auc']:.2f})")

plt.plot([0, 0.8], [0.8, 1], linestyle='--', color='gray', label='Random Guess')
plt.title('ROC Curves')
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.legend()
plt.grid(True)
plt.show()